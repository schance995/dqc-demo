{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schance995/dqc-demo/blob/main/mnist_dqc_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hybrid Quantum Transfer Learning with Pennylane, Jax, and Flax\n",
        "\n",
        "This demo shows how to train a dressed quantum circuit to classify MNIST with Jax, Flax, and HuggingFace. This demo shares some code with the multilabel chest X-ray classifier developed in https://arxiv.org/abs/2405.00156v2.\n"
      ],
      "metadata": {
        "id": "lrUSZq_-zyId"
      },
      "id": "lrUSZq_-zyId"
    },
    {
      "cell_type": "markdown",
      "id": "9a556c20",
      "metadata": {
        "id": "9a556c20"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane \"jax[cuda12]\" optax flax tqdm transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFVfNDetu08b",
        "outputId": "469f539e-5302-4b82-dae5-f5eb17abdbba"
      },
      "id": "rFVfNDetu08b",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.10/dist-packages (0.38.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (0.8.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: jax[cuda12] in /usr/local/lib/python3.10/dist-packages (0.4.33)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.3)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.15.1)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.6.12)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n",
            "Requirement already satisfied: pennylane-lightning>=0.38 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane) (24.1)\n",
            "Requirement already satisfied: jaxlib<=0.4.33,>=0.4.33 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]) (0.4.33)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]) (3.4.0)\n",
            "Requirement already satisfied: jax-cuda12-plugin<=0.4.33,>=0.4.33 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.33,>=0.4.33; extra == \"cuda12\"->jax[cuda12]) (0.4.33)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax) (0.1.87)\n",
            "Requirement already satisfied: etils[epy] in /usr/local/lib/python3.10/dist-packages (from optax) (1.9.4)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax) (1.0.8)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax) (0.6.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.66)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax) (13.9.1)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax) (0.12.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: jax-cuda12-pjrt==0.4.33 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin<=0.4.33,>=0.4.33->jax-cuda12-plugin[with_cuda]<=0.4.33,>=0.4.33; extra == \"cuda12\"->jax[cuda12]) (0.4.33)\n",
            "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.33,>=0.4.33; extra == \"cuda12\"->jax[cuda12]) (12.6.3.3)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12>=12.1.105 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.33,>=0.4.33; extra == \"cuda12\"->jax[cuda12]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cuda-nvcc-cu12>=12.1.105 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.33,>=0.4.33; extra == \"cuda12\"->jax[cuda12]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.33,>=0.4.33; extra == \"cuda12\"->jax[cuda12]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.1 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.33,>=0.4.33; extra == \"cuda12\"->jax[cuda12]) (9.4.0.58)\n",
            "Requirement already satisfied: nvidia-cufft-cu12>=11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.33,>=0.4.33; extra == \"cuda12\"->jax[cuda12]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12>=11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.33,>=0.4.33; extra == \"cuda12\"->jax[cuda12]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12>=12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.33,>=0.4.33; extra == \"cuda12\"->jax[cuda12]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12>=2.18.1 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.33,>=0.4.33; extra == \"cuda12\"->jax[cuda12]) (2.23.4)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12>=12.1.105 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.33,>=0.4.33; extra == \"cuda12\"->jax[cuda12]) (12.6.77)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (2.18.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (3.20.3)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (4.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epy]->optax) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epy]->optax) (3.20.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b9421ff3",
      "metadata": {
        "id": "b9421ff3"
      },
      "outputs": [],
      "source": [
        "from typing import Callable\n",
        "\n",
        "import jax\n",
        "import optax\n",
        "import pennylane as qml\n",
        "from datasets import load_dataset\n",
        "from flax import linen as nn\n",
        "from flax.training.train_state import TrainState\n",
        "from jax import numpy as jnp\n",
        "from jax import random as jrand\n",
        "from tqdm import tqdm\n",
        "from transformers import FlaxResNetModel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5612e1a",
      "metadata": {
        "id": "b5612e1a"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e616f8b5-5eb5-4117-9d08-947671a2d179",
      "metadata": {
        "id": "e616f8b5-5eb5-4117-9d08-947671a2d179"
      },
      "outputs": [],
      "source": [
        "N_QUBITS = 10\n",
        "N_LAYERS = 6\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bbbe3cc",
      "metadata": {
        "id": "0bbbe3cc"
      },
      "source": [
        "## Model implementation\n",
        "\n",
        "### Quantum circuit\n",
        "\n",
        "`jax.vmap` is used to enable batching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3aeb3b70-99a7-4874-ad4f-fb1ae3ba4342",
      "metadata": {
        "id": "3aeb3b70-99a7-4874-ad4f-fb1ae3ba4342"
      },
      "outputs": [],
      "source": [
        "def make_circuit(dev, n_qubits, n_layers):\n",
        "    @qml.qnode(dev)\n",
        "    def circuit(x, circuit_weights):\n",
        "        # data encoding\n",
        "        for i in range(n_qubits):\n",
        "            qml.Hadamard(wires=i)\n",
        "            qml.RY(x[i], wires=i)\n",
        "        # trainable unitary\n",
        "        for layer in range(n_layers):\n",
        "            for i in range(n_qubits):\n",
        "                qml.RY(circuit_weights[layer, i], wires=i)\n",
        "            qml.broadcast(qml.CNOT, wires=range(n_qubits), pattern='ring')\n",
        "\n",
        "        return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
        "\n",
        "    return jax.vmap(circuit, in_axes=(0, None))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b393123",
      "metadata": {
        "id": "9b393123"
      },
      "source": [
        "### Flax Linen wrapper for circuit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "94281e3f-a192-4aa1-a650-83bf1fe0ff25",
      "metadata": {
        "id": "94281e3f-a192-4aa1-a650-83bf1fe0ff25"
      },
      "outputs": [],
      "source": [
        "class QuantumCircuit(nn.Module):\n",
        "    num_qubits: int\n",
        "    num_layers: int\n",
        "    circuit: Callable\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        circuit_weights = self.param(\n",
        "            'circuit_weights',\n",
        "            nn.initializers.normal(),\n",
        "            (self.num_layers, self.num_qubits),\n",
        "        )\n",
        "        x = self.circuit(x, circuit_weights)\n",
        "        x = jnp.array(x).T\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9ffc7ff",
      "metadata": {
        "id": "f9ffc7ff"
      },
      "source": [
        "### Dressed quantum classifier\n",
        "\n",
        "Wraps a quantum circuit module with a transfer learning backbone and classical pre/post-processing layers. This implementation uses [Microsoft's ResNet-50](https://huggingface.co/microsoft/resnet-50) backbone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d2024263-11e1-4212-9bcd-72f9e450f877",
      "metadata": {
        "id": "d2024263-11e1-4212-9bcd-72f9e450f877"
      },
      "outputs": [],
      "source": [
        "class DressedQuantumClassifier(nn.Module):\n",
        "    backbone: nn.Module\n",
        "    circuit: Callable\n",
        "    num_qubits: int\n",
        "    num_layers: int\n",
        "    num_labels: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = x.pooler_output[:, :, 0, 0]\n",
        "        # reduce features to fit into quantum circuit\n",
        "        x = nn.Dense(features=self.num_qubits)(x)\n",
        "        # rescale inputs\n",
        "        x = jnp.tanh(x) * jnp.pi / 2\n",
        "        x = QuantumCircuit(\n",
        "            num_qubits=self.num_qubits,\n",
        "            num_layers=self.num_layers,\n",
        "            circuit=self.circuit,\n",
        "        )(x)\n",
        "        x = nn.Dense(features=self.num_labels)(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training, loss, and inference functions"
      ],
      "metadata": {
        "id": "f2fm5YbP6Rrn"
      },
      "id": "f2fm5YbP6Rrn"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7ad4684d-a14b-4947-b424-6aa13e4db646",
      "metadata": {
        "id": "7ad4684d-a14b-4947-b424-6aa13e4db646"
      },
      "outputs": [],
      "source": [
        "def create_train_step(model, params, optimizer):\n",
        "    state = TrainState.create(apply_fn=model.apply, params=params, tx=optimizer)\n",
        "\n",
        "    @jax.jit\n",
        "    def predict(params, x):\n",
        "        logits = model.apply(params, x)\n",
        "        return logits.argmax(axis=1)\n",
        "\n",
        "    @jax.jit\n",
        "    def loss_fn(params, x, y):\n",
        "        logits = model.apply(params, x)\n",
        "        loss = optax.softmax_cross_entropy_with_integer_labels(logits, y).mean()\n",
        "        return loss\n",
        "\n",
        "    @jax.jit\n",
        "    def train_step(state, x, y):\n",
        "        loss, grads = jax.value_and_grad(loss_fn)(state.params, x, y)\n",
        "        state = state.apply_gradients(grads=grads)\n",
        "        return state, loss\n",
        "\n",
        "    return train_step, loss_fn, predict, state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "375a78f3",
      "metadata": {
        "id": "375a78f3"
      },
      "source": [
        "## Create the dressed quantum circuit classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "db29f719",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db29f719",
        "outputId": "498c6d3d-6886-47d3-c74d-a1467ebcd9a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "dev = qml.device('default.qubit', wires=N_QUBITS)\n",
        "circuit = make_circuit(dev, N_QUBITS, N_LAYERS)\n",
        "\n",
        "resnet = FlaxResNetModel.from_pretrained('microsoft/resnet-50')\n",
        "\n",
        "dqc = DressedQuantumClassifier(\n",
        "    backbone=resnet.module,\n",
        "    circuit=circuit,\n",
        "    num_qubits=N_QUBITS,\n",
        "    num_layers=N_LAYERS,\n",
        "    num_labels=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5062b45",
      "metadata": {
        "id": "e5062b45"
      },
      "source": [
        "## Initialize classifier\n",
        "\n",
        "Requires any image, we use an array of 0s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8134af34",
      "metadata": {
        "id": "8134af34"
      },
      "outputs": [],
      "source": [
        "zero_image = jnp.empty((1, 224, 224, 3))\n",
        "key = jrand.PRNGKey(42)\n",
        "params = dqc.init(key, zero_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17828778",
      "metadata": {
        "id": "17828778"
      },
      "source": [
        "Transfer pre-trained weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0515cce4-bca3-40d9-8c2e-17099f0cc5ea",
      "metadata": {
        "id": "0515cce4-bca3-40d9-8c2e-17099f0cc5ea"
      },
      "outputs": [],
      "source": [
        "params['params']['backbone'] = resnet.params['params']\n",
        "params['batch_stats']['backbone'] = resnet.params['batch_stats']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8f121a1",
      "metadata": {
        "id": "f8f121a1"
      },
      "source": [
        "Create optimizer and get the model functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e326a02e-cf67-46a2-8dc1-dbc8c5fc6dd1",
      "metadata": {
        "id": "e326a02e-cf67-46a2-8dc1-dbc8c5fc6dd1"
      },
      "outputs": [],
      "source": [
        "optimizer = optax.adam(LEARNING_RATE)\n",
        "train_step, loss_fn, predict, state = create_train_step(dqc, params, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "060a0528",
      "metadata": {
        "id": "060a0528"
      },
      "source": [
        "## MNIST\n",
        "\n",
        "Download MNIST and format it to Jax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "62309490",
      "metadata": {
        "id": "62309490"
      },
      "outputs": [],
      "source": [
        "ds = load_dataset('mnist').with_format('jax')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1344063",
      "metadata": {
        "id": "a1344063"
      },
      "source": [
        "We will also format the 28x28 grayscale images to 224x224 RGB images normalized to ImageNet channel statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d5cef3b4-e7a3-445a-8f90-b211ea8018e5",
      "metadata": {
        "id": "d5cef3b4-e7a3-445a-8f90-b211ea8018e5"
      },
      "outputs": [],
      "source": [
        "@jax.vmap\n",
        "def grayscale_to_imagenet_format(x):\n",
        "    x /= 255\n",
        "    # resize to resnet size\n",
        "    x = jax.image.resize(x, (224, 224), method='nearest')\n",
        "    # copy grayscale channels to rgb\n",
        "    x = jnp.dstack([x] * 3)\n",
        "    # normalize to imagenet channels\n",
        "    x = (x - jnp.array((0.485, 0.456, 0.406))) / jnp.array((0.229, 0.224, 0.225))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "659a3675",
      "metadata": {
        "id": "659a3675"
      },
      "source": [
        "## Model loops\n",
        "\n",
        "Technical note on batch size: If the batch size doesn't divide evenly into the dataset size, the model functions will be recompiled every time the last batch is encountered as recompilation is triggered when the input shapes change.\n",
        "\n",
        "The solution is 1) drop some data so the batch size divides evenly into the dataset size or 2) use the interpreted functions on the unevenly sized batch and the compiled function on all other batches. The 2nd approach was used in https://arxiv.org/abs/2405.00156v2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train loop"
      ],
      "metadata": {
        "id": "fJ0qrUdWEhkm"
      },
      "id": "fJ0qrUdWEhkm"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0c2284cf",
      "metadata": {
        "id": "0c2284cf"
      },
      "outputs": [],
      "source": [
        "def train_loop(state, ds):\n",
        "    total_correct = 0\n",
        "    total_loss = 0\n",
        "    total_seen = 0\n",
        "    len_train = len(ds['train']) // BATCH_SIZE\n",
        "\n",
        "    # close progress bar when epoch is finished\n",
        "    with tqdm(ds['train'].iter(BATCH_SIZE), desc='train', leave=True, total=len_train) as pbar:\n",
        "        for batch in pbar:\n",
        "            x, y = batch['image'], batch['label']\n",
        "            x = grayscale_to_imagenet_format(x)\n",
        "\n",
        "            state, loss = train_step(state, x, y)\n",
        "            yhat = predict(state.params, x)\n",
        "\n",
        "            total_correct += int(sum(y == yhat))\n",
        "            total_loss += float(loss)\n",
        "            total_seen += len(yhat)\n",
        "\n",
        "            pbar.set_postfix({'Mean acc': float(total_correct / total_seen),\n",
        "                              'Mean loss': float(total_loss / total_seen)})\n",
        "            #break\n",
        "\n",
        "    return state # , float(total_loss / total_seen), float(total_correct / total_seen)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test loop"
      ],
      "metadata": {
        "id": "2yZbetl8EjLz"
      },
      "id": "2yZbetl8EjLz"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8d599cf8-97f5-43a2-8de4-7ea0ab72952e",
      "metadata": {
        "id": "8d599cf8-97f5-43a2-8de4-7ea0ab72952e"
      },
      "outputs": [],
      "source": [
        "def test_loop(state, ds):\n",
        "    total_correct = 0\n",
        "    total_loss = 0\n",
        "    total_seen = 0\n",
        "    len_test = len(ds['test']) // BATCH_SIZE\n",
        "\n",
        "    # close progress bar when epoch is finished\n",
        "    with tqdm(ds['test'].iter(BATCH_SIZE), desc='test', leave=True, total=len_test) as pbar:\n",
        "        for batch in pbar:\n",
        "            x, y = batch['image'], batch['label']\n",
        "            x = grayscale_to_imagenet_format(x)\n",
        "\n",
        "            yhat = predict(state.params, x)\n",
        "            loss = loss_fn(state.params, x, y)\n",
        "\n",
        "            total_correct += int(sum(y == yhat))\n",
        "            total_loss += float(loss)\n",
        "            total_seen += len(yhat)\n",
        "\n",
        "            pbar.set_postfix({'Mean acc': float(total_correct / total_seen),\n",
        "                              'Mean loss': float(total_loss / total_seen)})\n",
        "            #break\n",
        "\n",
        "    # return float(total_loss / total_seen), float(total_correct / total_seen)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03efe2ad",
      "metadata": {
        "id": "03efe2ad"
      },
      "source": [
        "## Model training and testing\n",
        "\n",
        "MNIST is easy, so we only run 1 training epoch to demonstrate the DQC implementation. The mean loss should go down and the mean accuracy should go up after training.\n",
        "\n",
        "It will take a few seconds for the model functions to get JIT-compiled, this is normal.\n",
        "\n",
        "This takes about 15 minutes on Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before training"
      ],
      "metadata": {
        "id": "siolyh87DrHG"
      },
      "id": "siolyh87DrHG"
    },
    {
      "cell_type": "code",
      "source": [
        "test_loop(state, ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfZaoUVxBSUV",
        "outputId": "87184591-04b1-4068-f870-fd5871803bf0"
      },
      "id": "tfZaoUVxBSUV",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test: 100%|██████████| 625/625 [01:17<00:00,  8.08it/s, Mean acc=0.118, Mean loss=0.144]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "WCsldsY5DlJ9"
      },
      "id": "WCsldsY5DlJ9"
    },
    {
      "cell_type": "code",
      "source": [
        "state = train_loop(state, ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcsNRn0aDek-",
        "outputId": "60a14fa0-6ddf-46b8-c334-a0ff529c3491"
      },
      "id": "qcsNRn0aDek-",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 3750/3750 [13:38<00:00,  4.58it/s, Mean acc=0.821, Mean loss=0.0522]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After training"
      ],
      "metadata": {
        "id": "MbEx9G9zDm3Z"
      },
      "id": "MbEx9G9zDm3Z"
    },
    {
      "cell_type": "code",
      "source": [
        "test_loop(state, ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8shkU1JtDfqC",
        "outputId": "8940bbf2-b43a-4b4e-9624-7e982c44f780"
      },
      "id": "8shkU1JtDfqC",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test: 100%|██████████| 625/625 [00:59<00:00, 10.44it/s, Mean acc=0.889, Mean loss=0.0316]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8f52686",
      "metadata": {
        "id": "e8f52686"
      },
      "source": [
        "## Your turn!\n",
        "\n",
        "Try different models, optimizers, circuits, datasets, etc. Can you find a quantum advantage?\n",
        "\n",
        "## References\n",
        "\n",
        "- [HuggingFace Flax tutorial](https://huggingface.co/blog/afmck/flax-tutorial)\n",
        "- [Flax Linen documentation](https://flax-linen.readthedocs.io/en/latest/index.html)\n",
        "- [Expanding the Horizon: Enabling Hybrid Quantum Transfer Learning for Long-Tailed Chest X-Ray Classification](https://arxiv.org/abs/2405.00156v2) \\([code](https://github.com/bioIntelligence-Lab/qumi)\\)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}